{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSDS 7331 Data Mining \n",
    "Lab 2\n",
    "July 08, 2018\n",
    "Group names: Travis Deason, Michael Landrum, & Vanessa Torres\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wine Reviews\n",
    "130k wine reviews with variety, location, winery, price and description\n",
    "\n",
    "https://www.kaggle.com/zynicide/wine-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from datetime import datetime, timedelta, date\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/vanessatorres/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "pstemmer = nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', '.Rapp.history', 'winemag-data-130k-v2.csv', 'winemag-data-130k-v2.json', 'winemag-data_first150k.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir(\"../vanessatorres/desktop/wine-reviews\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../vanessatorres/desktop/wine-reviews/winemag-data-130k-v2.csv\", encoding='ISO-8859-14')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>taster_name</th>\n",
       "      <th>taster_twitter_handle</th>\n",
       "      <th>title</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Aromas include tropical fruit, broom, brimston...</td>\n",
       "      <td>VulkÃ  Bianco</td>\n",
       "      <td>87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sicily &amp; Sardinia</td>\n",
       "      <td>Etna</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kerin OâKeefe</td>\n",
       "      <td>@kerinokeefe</td>\n",
       "      <td>Nicosia 2013 VulkÃ  Bianco  (Etna)</td>\n",
       "      <td>White Blend</td>\n",
       "      <td>Nicosia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>This is ripe and fruity, a wine that is smooth...</td>\n",
       "      <td>Avidagos</td>\n",
       "      <td>87</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Douro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>@vossroger</td>\n",
       "      <td>Quinta dos Avidagos 2011 Avidagos Red (Douro)</td>\n",
       "      <td>Portuguese Red</td>\n",
       "      <td>Quinta dos Avidagos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>US</td>\n",
       "      <td>Tart and snappy, the flavors of lime flesh and...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Paul Gregutt</td>\n",
       "      <td>@paulgwineÂ</td>\n",
       "      <td>Rainstorm 2013 Pinot Gris (Willamette Valley)</td>\n",
       "      <td>Pinot Gris</td>\n",
       "      <td>Rainstorm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>US</td>\n",
       "      <td>Pineapple rind, lemon pith and orange blossom ...</td>\n",
       "      <td>Reserve Late Harvest</td>\n",
       "      <td>87</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>Lake Michigan Shore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alexander Peartree</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St. Julian 2013 Reserve Late Harvest Riesling ...</td>\n",
       "      <td>Riesling</td>\n",
       "      <td>St. Julian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>US</td>\n",
       "      <td>Much like the regular bottling from 2012, this...</td>\n",
       "      <td>Vintner's Reserve Wild Child Block</td>\n",
       "      <td>87</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Paul Gregutt</td>\n",
       "      <td>@paulgwineÂ</td>\n",
       "      <td>Sweet Cheeks 2012 Vintner's Reserve Wild Child...</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>Sweet Cheeks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   country                                        description  \\\n",
       "0           0     Italy  Aromas include tropical fruit, broom, brimston...   \n",
       "1           1  Portugal  This is ripe and fruity, a wine that is smooth...   \n",
       "2           2        US  Tart and snappy, the flavors of lime flesh and...   \n",
       "3           3        US  Pineapple rind, lemon pith and orange blossom ...   \n",
       "4           4        US  Much like the regular bottling from 2012, this...   \n",
       "\n",
       "                          designation  points  price           province  \\\n",
       "0                       VulkÃ  Bianco      87    NaN  Sicily & Sardinia   \n",
       "1                            Avidagos      87   15.0              Douro   \n",
       "2                                 NaN      87   14.0             Oregon   \n",
       "3                Reserve Late Harvest      87   13.0           Michigan   \n",
       "4  Vintner's Reserve Wild Child Block      87   65.0             Oregon   \n",
       "\n",
       "              region_1           region_2         taster_name  \\\n",
       "0                 Etna                NaN     Kerin OâKeefe   \n",
       "1                  NaN                NaN          Roger Voss   \n",
       "2    Willamette Valley  Willamette Valley        Paul Gregutt   \n",
       "3  Lake Michigan Shore                NaN  Alexander Peartree   \n",
       "4    Willamette Valley  Willamette Valley        Paul Gregutt   \n",
       "\n",
       "  taster_twitter_handle                                              title  \\\n",
       "0          @kerinokeefe                 Nicosia 2013 VulkÃ  Bianco  (Etna)   \n",
       "1            @vossroger      Quinta dos Avidagos 2011 Avidagos Red (Douro)   \n",
       "2          @paulgwineÂ       Rainstorm 2013 Pinot Gris (Willamette Valley)   \n",
       "3                   NaN  St. Julian 2013 Reserve Late Harvest Riesling ...   \n",
       "4          @paulgwineÂ   Sweet Cheeks 2012 Vintner's Reserve Wild Child...   \n",
       "\n",
       "          variety               winery  \n",
       "0     White Blend              Nicosia  \n",
       "1  Portuguese Red  Quinta dos Avidagos  \n",
       "2      Pinot Gris            Rainstorm  \n",
       "3        Riesling           St. Julian  \n",
       "4      Pinot Noir         Sweet Cheeks  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 129971 entries, 0 to 129970\n",
      "Data columns (total 14 columns):\n",
      "Unnamed: 0               129971 non-null int64\n",
      "country                  129908 non-null object\n",
      "description              129971 non-null object\n",
      "designation              92506 non-null object\n",
      "points                   129971 non-null int64\n",
      "price                    120975 non-null float64\n",
      "province                 129908 non-null object\n",
      "region_1                 108724 non-null object\n",
      "region_2                 50511 non-null object\n",
      "taster_name              103727 non-null object\n",
      "taster_twitter_handle    98758 non-null object\n",
      "title                    129971 non-null object\n",
      "variety                  129970 non-null object\n",
      "winery                   129971 non-null object\n",
      "dtypes: float64(1), int64(2), object(11)\n",
      "memory usage: 13.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0 129971\n",
      "country 44\n",
      "description 119955\n",
      "designation 37980\n",
      "points 21\n",
      "price 391\n",
      "province 426\n",
      "region_1 1230\n",
      "region_2 18\n",
      "taster_name 20\n",
      "taster_twitter_handle 16\n",
      "title 118840\n",
      "variety 708\n",
      "winery 16757\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(col, df[col].unique().size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preparation 1 (10pts)\n",
    "\n",
    "Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of our models we wanted to see if we could classify wines based on the specific region, a sommlier's description and variety. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sent_tokenizer = nltk.data.load(df['description']) # i may want this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = df.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "swords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vecs = reviews\\\n",
    "    .apply(lambda x: [re.sub(\"[\\W]\", '', i).lower().strip() for i in x.split()])\\\n",
    "    .apply(lambda x: [ps.stem(i) for i in x if i not in swords and len(i) > 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46077    [creami, textur, ripe, muscadet, domin, charac...\n",
       "34232    [easi, gentl, wine, drink, softli, tannic, che...\n",
       "76682    [rubberi, rustic, nose, start, stalki, gritti,...\n",
       "23835    [creami, refin, offer, aroma, fragrant, wild, ...\n",
       "42275    [subtli, earthi, dusti, miner, mingl, press, a...\n",
       "45230    [ripe, round, wine, touch, oygen, give, extra,...\n",
       "52999    [soft, rich, wine, offer, dusti, tannin, well,...\n",
       "90988    [despit, silki, mediumbodi, textur, pinot, tou...\n",
       "68349    [pinot, nero, open, aroma, berri, rose, petal,...\n",
       "32015    [deepli, impress, bordeaux, blend, come, small...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vecs.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85976     [exot, chardonnay, reminisc, rhãṁne, white, wi...\n",
       "14624     [ripe, rich, velveti, wine, show, lack, restra...\n",
       "15924     [stoni, miner, note, accent, fragrant, blossom...\n",
       "100700    [balanc, ripe, structur, fine, reflect, miner,...\n",
       "12607     [brand, recentlycr, appel, part, beaujolai, wi...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vecs.apply(lambda x: [ps.stem(i) for i in x]).sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/vanessatorres/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129971,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "none                  0.201922\n",
       "Roger Voss            0.196305\n",
       "Michael Schachner     0.116441\n",
       "Kerin OâKeefe       0.082911\n",
       "Virginie Boone        0.073378\n",
       "Paul Gregutt          0.073339\n",
       "Matt Kettmann         0.048719\n",
       "Joe Czerwinski        0.039601\n",
       "Sean P. Sullivan      0.038209\n",
       "Anna Lee C. Iijima    0.033969\n",
       "Jim Gordon            0.032138\n",
       "Anne KrebiehlÂ MW     0.028352\n",
       "Lauren Buzzeo         0.014119\n",
       "Susan Kostrzewa       0.008348\n",
       "Mike DeSimone         0.003955\n",
       "Jeff Jenssen          0.003778\n",
       "Alexander Peartree    0.003193\n",
       "Carrie Dykes          0.001069\n",
       "Fiona Adams           0.000208\n",
       "Christina Pickard     0.000046\n",
       "Name: taster_name, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['taster_name'].fillna('none').value_counts(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nona = df[df['taster_name'].fillna('N') != 'N']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {val: idx for idx, val in enumerate(df['taster_name'].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_nona['taster_name'].replace(label_map).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = df_nona.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "swords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vecs = reviews\\\n",
    "    .apply(lambda x: [re.sub(\"[\\W]\", '', i).lower().strip() for i in x.split()])\\\n",
    "    .apply(lambda x: [ps.stem(i) for i in x if i not in swords and len(i) > 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18731     [gremillet, prestig, cuvã, made, chardonnay, b...\n",
       "95138     [slight, cloudi, signal, natur, wine, smell, f...\n",
       "17971     [opengrain, aroma, front, follow, sweeter, sce...\n",
       "108587    [even, best, txakoli, wont, appeal, everyon, r...\n",
       "62381     [2006, chilean, chardonnay, past, prime, mont,...\n",
       "53595     [alway, loio, bright, fruiti, wine, readi, dri...\n",
       "96541     [smell, full, also, soupi, stew, herbal, textu...\n",
       "46031     [occasion, produc, reservelevel, wine, mysteri...\n",
       "81070     [show, charact, upfront, start, aroma, cedar, ...\n",
       "3592      [reach, matur, wine, show, tannin, soften, spi...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vecs.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "back2sent = word_vecs.apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = TfidfVectorizer(lowercase=False, min_df=.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_matrix = transform.fit_transform(back2sent.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preparation 2 (5pts)\n",
    "Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created).\n",
    "\n",
    "For our models, we used region_2, taster_name, variety."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling and Evaluation 1 (10pts)\n",
    "Choose and explain your evaluation metrics that you will use (i.e., accuracy, precision, recall, F-measure, or any metric we have discussed). Why are the measure(s) appropriate for analyzing the results of your modeling? Give a detailed explanation backing up any assertions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19201608, 0.        , 0.34717677, 0.27458416, 0.18116137,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.29985157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.65153631, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.16273315, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.29726321, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.268779  , 0.        , 0.18133404, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.38723122, 0.        , 0.2020623 ,\n",
       "        0.        , 0.        , 0.26549608, 0.        , 0.30890153,\n",
       "        0.        , 0.        , 0.        , 0.36933033, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.20256938, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.29978854, 0.        , 0.2022549 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.38014253, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.23043025, 0.        , 0.        , 0.37079453, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.36949968, 0.        , 0.31942556, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.30430609, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.20071423, 0.        ,\n",
       "        0.21837719, 0.38778599, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.38953712, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.2772369 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.44931376],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.2361112 ,\n",
       "        0.        , 0.        , 0.        , 0.3936494 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.19493863, 0.        ,\n",
       "        0.21209333, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.4323183 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.33107894,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.64015203, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.53768421, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.25611691, 0.3852281 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.20512234, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.35184923, 0.        , 0.        , 0.28690586,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.32123563, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.34374959, 0.        , 0.16539342,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.303986  ,\n",
       "        0.        , 0.        , 0.        , 0.50681165, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.38051115, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.25097756, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.30427575, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.41208815, 0.        , 0.        , 0.        ,\n",
       "        0.34666323, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.24572388,\n",
       "        0.        , 0.        ],\n",
       "       [0.23364247, 0.        , 0.        , 0.33411016, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.33698809,\n",
       "        0.        , 0.42039412, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.18199569, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.28464374, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.30909697,\n",
       "        0.26817071, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.35398559, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.32377833, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.17818599,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.26367781,\n",
       "        0.        , 0.38045557, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.29791924,\n",
       "        0.        , 0.        , 0.        , 0.21769823, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.26392914, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.32077841, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.44437609,\n",
       "        0.        , 0.        , 0.        , 0.4838621 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.21314118,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.29497486, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.33161639, 0.        , 0.        , 0.        , 0.21988726,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.17481775, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.34586563, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.27289154,\n",
       "        0.        , 0.        , 0.        , 0.28757664, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.28585323, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.32695866, 0.3233837 , 0.15731455,\n",
       "        0.        , 0.35968969],\n",
       "       [0.25287575, 0.        , 0.        , 0.36161387, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.3993044 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.26956291,\n",
       "        0.        , 0.        , 0.        , 0.19697744, 0.        ,\n",
       "        0.21431157, 0.        , 0.        , 0.40041184, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.42349856, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.38570827,\n",
       "        0.        , 0.        ]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_matrix.toarray()[:1000:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_train = np.random.random(word_vecs.shape[0]) < .8\n",
    "Xtr = tf_idf_matrix[test_train]\n",
    "Xte = tf_idf_matrix[~test_train]\n",
    "ytr = y[test_train]\n",
    "yte = y[~test_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtr.toarray(), ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20697, 19)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(Xte.toarray()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4366333285017152"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(Xte.toarray(), yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_matrixtf_idf_m  = transform.fit_transform(back2sent.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling and Evaluation 2 (10pts)\n",
    "\n",
    "Choose the method you will use for dividing your data into training and testing splits (i.e., are you using Stratified 10-fold cross validation? Why?). Explain why your chosen method is appropriate or use more than one method as appropriate. For example, if you are using time series data then you should be using continuous training and testing sets across time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used a train test split with a 20% hold out for model evaluation. Since we are using a multiclass classification our focus was on accuracy and not precision. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## build train_test_split\n",
    "test_train = np.random.random(word_vecs.shape[0]) < .8\n",
    "Xtr = tf_idf_matrix[test_train]\n",
    "Xte = tf_idf_matrix[~test_train]\n",
    "ytr = y[test_train]\n",
    "yte = y[~test_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling and Evaluation 3 (20pts)\n",
    "Create three different classification/regression models for each task (e.g., random forest, KNN, and SVM for task one and the same or different algorithms for task two). Two modeling techniques must be new (but the third could be SVM or logistic regression). Adjust parameters as appropriate to increase generalization performance using your chosen metric. You must investigate different parameters of the algorithms!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian Naiive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3870296933939453\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "modelgb = GaussianNB()\n",
    "modelgb.fit(Xtr.toarray(), ytr)\n",
    "print(modelgb.score(Xte.toarray(), yte))\n",
    "print((datetime.now() - start).seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7472192668536609\n",
      "729\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "model_svm = SVC(C=1.0, kernel='rbf', degree=3, gamma=.05)\n",
    "model_svm.fit(Xtr.toarray(), ytr)\n",
    "print( model_svm.score(Xte.toarray(), yte))\n",
    "print((datetime.now()-start).seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7515717187348874\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "## 50 Tree model\n",
    "start = datetime.now()\n",
    "modelrf100 = RandomForestClassifier(n_estimators=50, n_jobs=-1).fit(Xtr.toarray(), ytr)\n",
    "print(RandomForestClassifier(n_estimators=50, n_jobs=-1).fit(Xtr.toarray(), ytr)\\\n",
    "    .score(Xte.toarray(), yte))\n",
    "# modelrf100.fit(Xtr.toarray(), ytr)\n",
    "# print(modelrf100.score(Xte.toarray(), yte))\n",
    "print((datetime.now() - start).seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7569881032981913\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "### 250 Tree model\n",
    "start = datetime.now()\n",
    "modelrf250 = RandomForestClassifier(n_estimators=250, n_jobs=-1)\n",
    "modelrf250.fit(Xtr.toarray(), ytr)\n",
    "print(modelrf250.score(Xte.toarray(), yte))\n",
    "print((datetime.now() - start).seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7599380984621337\n",
      "136\n"
     ]
    }
   ],
   "source": [
    "### 1000 Tree Model\n",
    "start = datetime.now()\n",
    "modelrf1k = RandomForestClassifier(n_estimators=1000, n_jobs=-1)\n",
    "modelrf1k.fit(Xtr.toarray(), ytr)\n",
    "print(modelrf1k.score(Xte.toarray(), yte))\n",
    "print((datetime.now() - start).seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GradientBoosted Decision Trees Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now()\n",
    "modelgbf_t250 = GradientBoostingClassifier(max_depth=5,\n",
    "                                           learning_rate=.1, \n",
    "                                           n_estimators=250)\n",
    "modelgbf_t250.fit(Xtr.toarray(), ytr)\n",
    "print(modelgbf_t250.score(Xte.toarray(), yte))\n",
    "print((datetime.now() - start).seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimizing Document Frequency**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = ndf.description\n",
    "y = ndf[y_col] == 'pinot noir'\n",
    "\n",
    "swords = set(stopwords.words('english'))\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "word_vecs = reviews\\\n",
    "    .apply(lambda x: [re.sub(\"[\\W]\", '', i).lower().strip() for i in x.split()])\\\n",
    "    .apply(lambda x: [ps.stem(i) for i in x if i not in swords and len(i) > 3])\n",
    "\n",
    "back2sent = word_vecs.apply(lambda x: ' '.join(x))\n",
    "\n",
    "test_train = np.random.random(ndf.shape[0]) < .8\n",
    "ytr = y[test_train]\n",
    "yte = y[~test_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoresdf = {}\n",
    "for key in scores.keys():\n",
    "    scoresdf[key] = pd.DataFrame(scores[key])\n",
    "    scoresdf[key].columns = ['min_df', 'time_taken', 'score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(16,8))\n",
    "colors =[None, 'black', 'red', 'blue']\n",
    "for key, vals in scoresdf.items():\n",
    "    plt.plot(vals['min_df'], vals['score'], color=colors[key], label=key)\n",
    "plt.legend(fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoresdf = {}\n",
    "for key in scores.keys():\n",
    "    scoresdf[key] = pd.DataFrame(scores[key])\n",
    "    scoresdf[key].columns = ['min_df', 'time_taken', 'num_cols', 'score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoresdf[1].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot of Minimum Document Frequency vs Model Accuracy**\n",
    "    - Colors represent n-gram size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(16,8))\n",
    "colors =[None, 'black', 'red', 'blue']\n",
    "for key, vals in scoresdf.items():\n",
    "    plt.plot(vals['min_df'], vals['score'], color=colors[key], label=key)\n",
    "plt.legend(fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Number of Features**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot of number of total features vs Model accuracy**\n",
    "    - Colors represent max number of n-grams allowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoresdf_nfeats = {}\n",
    "for key in feat_scores.keys():\n",
    "    scoresdf_nfeats[key] = pd.DataFrame(feat_scores[key])\n",
    "    scoresdf_nfeats[key].columns = ['max_features', 'time_taken', 'num_cols', 'score']\n",
    "    \n",
    "fig, ax = plt.subplots(1,1, figsize=(16,8))\n",
    "colors =[None, 'black', 'red', 'blue']\n",
    "for key, vals in scoresdf_nfeats.items():\n",
    "    plt.plot(vals['max_features'], vals['score'], color=colors[key], label=key)\n",
    "plt.legend(fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scoresdf_nfeats[1]['time_taken']\n",
    "      + scoresdf_nfeats[2]['time_taken'] +\n",
    "      scoresdf_nfeats[3]['time_taken'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Number of Trees**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoresdf = pd.DataFrame(tree_scores)\n",
    "scoresdf.columns = ['n_estimators', 'time_taken', 'num_cols', 'score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot of number of trees vs Model Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoresdf.set_index('n_estimators')['score'].plot(figsize=(16,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Max Tree Depth**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depthdf = pd.DataFrame(depth_scores)\n",
    "depthdf.columns = ['max_depth', 'time_taken', 'num_cols', 'score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depthdf.set_index('max_depth')['score'].plot(figsize=(16,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learning Rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scores_df = pd.DataFrame(lr_scores)\n",
    "lr_scores_df.columns = ['learn_rate', 'time_taken', 'num_cols', 'score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot of Learning Rate vs Model Accuracy with 100 trees max depth of 10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scores_df.set_index('learn_rate')['score'].plot(figsize=(16,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimal model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {val: idx for idx, val in enumerate(ndf[y_col].unique())}\n",
    "y = df_noblends[y_col].replace(label_map).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val = df_noblends['variety'].value_counts().tail(1).values[0]\n",
    "\n",
    "print(min_val)\n",
    "list_of_dfs = []\n",
    "for x in df_noblends[y_col].unique():\n",
    "    list_of_dfs.append(df_noblends[df_noblends[y_col] == x].sample(min_val))\n",
    "ndf_all = pd.concat(list_of_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = ndf.description\n",
    "swords = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "\n",
    "word_vecs = reviews\\\n",
    "    .apply(lambda x: [re.sub(\"[\\W]\", '', i).lower().strip() for i in x.split()])\\\n",
    "    .apply(lambda x: [ps.stem(i) for i in x if i not in swords and len(i) > 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "back2sent = word_vecs.apply(lambda x: ' '.join(x))\n",
    "transform = TfidfVectorizer(lowercase=False, max_df=.1, max_features=2000, ngram_range=(1,3))\n",
    "tf_idf_matrix = transform.fit_transform(back2sent.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_matrix.toarray()[:1000:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate Cross validation set\n",
    "rand_vals = np.random.random(word_vecs.shape[0])\n",
    "\n",
    "cv_set = []\n",
    "k= 5\n",
    "\n",
    "for val in np.linspace(0,1-1/k,k):\n",
    "    test_train = ((rand_vals <= val) | (rand_vals > val + 1.0/k))\n",
    "    cv_set.append({'Xtr': tf_idf_matrix[test_train],\n",
    "                    'Xte': tf_idf_matrix[~test_train],\n",
    "                    'ytr': y[test_train],\n",
    "                    'yte': y[~test_train]\n",
    "                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check Identified Optimal model parameters on Cross-validated set (k= 5)\n",
    "mod_params = {'max_depth':25, 'learning_rate':.1, 'n_estimators' :3000, 'n_jobs': -1}\n",
    "cv_scores = []\n",
    "\n",
    "for tt_set in cv_set:\n",
    "    cv_scores.append(xgb.XGBClassifier(**mod_params)\\\n",
    "                        .fit(tt_set['Xtr'].toarray(), tt_set['ytr'])\\\n",
    "                        .score(tt_set['Xte'].toarray(), tt_set['yte']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(cv_scores).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling and Evaluation 5 (10pts)\n",
    "\n",
    "Discuss the advantages of each model for each classification task, if any. If there are not advantages, explain why. Is any model better than another? Is the difference significant with 95% confidence? Use proper statistical comparison methods. You must use statistical comparison techniques—be sure they are appropriate for your chosen method of validation as discussed in unit 7 of the course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to go with XGBoost for our text classification because when using a 1000 estimators, XGBoost gave us ~56% while Random Forrest gave us 44%, when using 12 classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling and Evaluation 6 (10pts)\n",
    "\n",
    "Which attributes from your analysis are most important? Use proper methods discussed in class to evaluate the importance of different attributes. Discuss the results and hypothesize about why certain attributes are more important than others for a given classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our final model had a total 2000 features and we performed ensemble modeling, it is difficult to accurately measure feature importance. Due to time constraints, computing 2000 features, would take about 250 days; if we left 1 in, 1 out. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deployment (5pts)\n",
    "\n",
    "How useful is your model for interested parties (i.e., the companies or organizations that might want to use it for prediction)? How would you measure the model's value if it was used by these parties? How would your deploy your model for interested parties? What other data should be collected? How often would the model need to be updated, etc.?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our models, winerys and sommliers would be interested in using our analysis in order to help choose a fraud-prevention system. To this point, radio frequency identification technology is likely to be a major development in security devices. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exceptional Work (10pts)\n",
    "\n",
    "You have free reign to provide additional analyses. One idea: grid search parameters in a parallelized fashion and visualize the performances across attributes. Which parameters are most significant for making a good model for each classification algorithm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
